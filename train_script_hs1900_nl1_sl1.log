Namespace(init_path='UniRep/1900_weights', n_layers=1, num_iters=1000, rnn_size=1900, save_dir='1000_iters_hs1900_nl4_pt', site_loss=True)
Uniprot data had already been processed. Loading from csv
WARNING:tensorflow:From /clusterfs/mhg/sprasad/CTA/geometries/UniRep_finetune_forest/UniRep/unirep.py:113: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.
Instructions for updating:
dim is deprecated, use axis instead
2020-05-07 14:24:01.554219: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-05-07 14:24:01.554309: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel driver does not appear to be running on this host (n0071.mhg0): /proc/driver/nvidia/version does not exist
Size of training data: 49839, size of test data: 12460
WARNING:tensorflow:From /global/software/sl-7.x86_64/modules/apps/ml/tensorflow/1.12.0-py36/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py:1165: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /clusterfs/mhg/sprasad/CTA/geometries/UniRep_finetune_forest/UniRep/data_utils.py:190: group_by_window (from tensorflow.contrib.data.python.ops.grouping) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.experimental.group_by_window(...)`.
START OF TRAINING FOR 1000 ITERATIONS
Iteration 0, loss 2.5929672718048096, site loss 1.0676860809326172
Iteration 1, loss 2.704669713973999, site loss 0.4435790777206421
Iteration 2, loss 2.713545799255371, site loss 0.16505098342895508
Iteration 3, loss 2.70910382270813, site loss 0.10308222472667694
Iteration 4, loss 2.700969934463501, site loss 0.08681045472621918
Iteration 5, loss 2.6620185375213623, site loss 0.07863403856754303
Iteration 6, loss 2.664238929748535, site loss 0.07171089202165604
Iteration 7, loss 2.635643243789673, site loss 0.07674207538366318
Iteration 8, loss 2.6309428215026855, site loss 0.06643564254045486
Iteration 9, loss 2.615837574005127, site loss 0.06883750855922699
Iteration 10, loss 2.602715253829956, site loss 0.06896961480379105
Iteration 11, loss 2.5798909664154053, site loss 0.06636545062065125
Iteration 12, loss 2.592695713043213, site loss 0.06609219312667847
Iteration 13, loss 2.530251979827881, site loss 0.0660652220249176
Iteration 14, loss 2.546976327896118, site loss 0.06405439972877502
Iteration 15, loss 2.526524066925049, site loss 0.06569451838731766
Iteration 16, loss 2.5072519779205322, site loss 0.06072651222348213
Iteration 17, loss 2.480604648590088, site loss 0.06363058090209961
Iteration 18, loss 2.4677085876464844, site loss 0.06100377440452576
Iteration 19, loss 2.4751791954040527, site loss 0.06011037528514862
Iteration 20, loss 2.4574713706970215, site loss 0.0549372136592865
Iteration 21, loss 2.453951358795166, site loss 0.059868086129426956
Iteration 22, loss 2.467193126678467, site loss 0.05894064903259277
Iteration 23, loss 2.474348545074463, site loss 0.06262984126806259
Iteration 24, loss 2.429335117340088, site loss 0.05833527073264122
Iteration 25, loss 2.4595725536346436, site loss 0.058792177587747574
Iteration 26, loss 2.410369396209717, site loss 0.05633805692195892
Iteration 27, loss 2.409569263458252, site loss 0.059038519859313965
Iteration 28, loss 2.438493490219116, site loss 0.05336727201938629
Iteration 29, loss 2.43607234954834, site loss 0.05669177323579788
Iteration 30, loss 2.4119396209716797, site loss 0.05587393790483475
Iteration 31, loss 2.394449234008789, site loss 0.05432196706533432
Iteration 32, loss 2.3859262466430664, site loss 0.05709928274154663
Iteration 33, loss 2.3899338245391846, site loss 0.054905541241168976
Iteration 34, loss 2.3953070640563965, site loss 0.05587087944149971
Iteration 35, loss 2.390611410140991, site loss 0.057356275618076324
Iteration 36, loss 2.3321752548217773, site loss 0.04974079132080078
Iteration 37, loss 2.384962558746338, site loss 0.05620891600847244
Iteration 38, loss 2.3473753929138184, site loss 0.05321222543716431
Iteration 39, loss 2.3329973220825195, site loss 0.054689668118953705
Iteration 40, loss 2.3583459854125977, site loss 0.05184454470872879
Iteration 41, loss 2.358670234680176, site loss 0.056418221443891525
Iteration 42, loss 2.3552284240722656, site loss 0.058392785489559174
Iteration 43, loss 2.366793394088745, site loss 0.05184813216328621
Iteration 44, loss 2.3293681144714355, site loss 0.059000954031944275
Iteration 45, loss 2.378809928894043, site loss 0.05232468992471695
Iteration 46, loss 2.325444459915161, site loss 0.048722852021455765
Iteration 47, loss 2.3227806091308594, site loss 0.055168554186820984
Iteration 48, loss 2.3355541229248047, site loss 0.0538242906332016
Iteration 49, loss 2.3274900913238525, site loss 0.05123809725046158
Iteration 50, loss 2.3512368202209473, site loss 0.050028495490550995
Iteration 51, loss 2.3501009941101074, site loss 0.05366474390029907
Iteration 52, loss 2.331801176071167, site loss 0.05475062504410744
Iteration 53, loss 2.280883312225342, site loss 0.05154137313365936
Iteration 54, loss 2.318789482116699, site loss 0.050499480217695236
Iteration 55, loss 2.3090624809265137, site loss 0.04644526168704033
Iteration 56, loss 2.316575527191162, site loss 0.055503081530332565
Iteration 57, loss 2.308290481567383, site loss 0.05152361840009689
Iteration 58, loss 2.2706522941589355, site loss 0.04561262205243111
Iteration 59, loss 2.267549991607666, site loss 0.0520600900053978
Iteration 60, loss 2.3045783042907715, site loss 0.04701995104551315
Iteration 61, loss 2.2908129692077637, site loss 0.0463574156165123
Iteration 62, loss 2.2444186210632324, site loss 0.04999735951423645
Iteration 63, loss 2.2665505409240723, site loss 0.04565539211034775
Iteration 64, loss 2.320707321166992, site loss 0.04988475143909454
Iteration 65, loss 2.2569828033447266, site loss 0.04903320595622063
Iteration 66, loss 2.260723829269409, site loss 0.04575987905263901
Iteration 67, loss 2.3157949447631836, site loss 0.04419495165348053
Iteration 68, loss 2.1959986686706543, site loss 0.047920092940330505
Iteration 69, loss 2.2341606616973877, site loss 0.04535495117306709
Iteration 70, loss 2.2119696140289307, site loss 0.044597022235393524
Iteration 71, loss 2.1731667518615723, site loss 0.04360732436180115
Iteration 72, loss 2.2278122901916504, site loss 0.04639686271548271
Iteration 73, loss 2.2538633346557617, site loss 0.04925772175192833
Iteration 74, loss 2.162834644317627, site loss 0.043693818151950836
Iteration 75, loss 2.2308430671691895, site loss 0.04400869831442833
Iteration 76, loss 2.2197964191436768, site loss 0.04540848359465599
Iteration 77, loss 2.1838271617889404, site loss 0.04557427018880844
Iteration 78, loss 2.1811575889587402, site loss 0.0406346432864666
Iteration 79, loss 2.2122015953063965, site loss 0.04131403937935829
Iteration 80, loss 2.1954898834228516, site loss 0.04110238701105118
Iteration 81, loss 2.21293306350708, site loss 0.04592064768075943
Iteration 82, loss 2.2486555576324463, site loss 0.04381180554628372
Iteration 83, loss 2.1910552978515625, site loss 0.04274791479110718
Iteration 84, loss 2.267186164855957, site loss 0.04239588975906372
Iteration 85, loss 2.2247142791748047, site loss 0.042016349732875824
Iteration 86, loss 2.246879816055298, site loss 0.04546316713094711
Iteration 87, loss 2.2142720222473145, site loss 0.046189405024051666
Iteration 88, loss 2.274979591369629, site loss 0.04508962854743004
Iteration 89, loss 2.29266357421875, site loss 0.0478072389960289
Iteration 90, loss 2.2180941104888916, site loss 0.04453607648611069
Iteration 91, loss 2.2476563453674316, site loss 0.045236557722091675
Iteration 92, loss 2.2425501346588135, site loss 0.04622458666563034
Iteration 93, loss 2.2271342277526855, site loss 0.04707914590835571
Iteration 94, loss 2.2245380878448486, site loss 0.04426433891057968
Iteration 95, loss 2.2505855560302734, site loss 0.045938193798065186
Iteration 96, loss 2.2724521160125732, site loss 0.04511532559990883
Iteration 97, loss 2.2199838161468506, site loss 0.04388830438256264
Iteration 98, loss 2.2505855560302734, site loss 0.044591762125492096
Iteration 99, loss 2.224865674972534, site loss 0.03962618112564087
Iteration 100, loss 2.23730731010437, site loss 0.04298597574234009
Iteration 101, loss 2.2193045616149902, site loss 0.04589645937085152
Iteration 102, loss 2.1949737071990967, site loss 0.0382002517580986
Iteration 103, loss 2.25457763671875, site loss 0.046187013387680054
Iteration 104, loss 2.182483434677124, site loss 0.03861474245786667
Iteration 105, loss 2.214322566986084, site loss 0.04494985193014145
Iteration 106, loss 2.759705066680908, site loss 0.09434182196855545
Iteration 107, loss 2.279865264892578, site loss 0.04536423087120056
Iteration 108, loss 2.2273993492126465, site loss 0.04377129673957825
Iteration 109, loss 2.270533800125122, site loss 0.043188877403736115
Iteration 110, loss 2.2141125202178955, site loss 0.03987004980444908
Iteration 111, loss 2.2683634757995605, site loss 0.0416894406080246
Iteration 112, loss 2.1781888008117676, site loss 0.04646551236510277
Iteration 113, loss 2.2184762954711914, site loss 0.042184893041849136
Iteration 114, loss 2.2536492347717285, site loss 0.04330495744943619
Iteration 115, loss 2.209660053253174, site loss 0.03965382277965546
Iteration 116, loss 2.2593376636505127, site loss 0.0409846268594265
Iteration 117, loss 2.206101894378662, site loss 0.04038819670677185
Iteration 118, loss 2.2187886238098145, site loss 0.03965941071510315
Iteration 119, loss 2.1815285682678223, site loss 0.040415216237306595
Iteration 120, loss 2.2739477157592773, site loss 0.04077652096748352
Iteration 121, loss 2.195082426071167, site loss 0.03954330086708069
Iteration 122, loss 2.1956334114074707, site loss 0.04105761647224426
Iteration 123, loss 2.209057331085205, site loss 0.040806740522384644
Iteration 124, loss 2.241137981414795, site loss 0.03724022954702377
Iteration 125, loss 2.1723239421844482, site loss 0.03736943006515503
Iteration 126, loss 2.2031960487365723, site loss 0.04113945737481117
Iteration 127, loss 2.1595730781555176, site loss 0.037863485515117645
Iteration 128, loss 2.259735345840454, site loss 0.03851371631026268
Iteration 129, loss 2.1648471355438232, site loss 0.03794942796230316
Iteration 130, loss 2.1480133533477783, site loss 0.03704134374856949
Iteration 131, loss 2.152320384979248, site loss 0.03917120769619942
Iteration 132, loss 2.118821144104004, site loss 0.03805626556277275
Iteration 133, loss 2.1474857330322266, site loss 0.037398334592580795
Iteration 134, loss 2.14013671875, site loss 0.03512338548898697
Iteration 135, loss 2.1806421279907227, site loss 0.03496447205543518
Iteration 136, loss 2.177338123321533, site loss 0.038478732109069824
Iteration 137, loss 2.1254758834838867, site loss 0.033460814505815506
Iteration 138, loss 2.2050743103027344, site loss 0.03578971326351166
Iteration 139, loss 2.1692094802856445, site loss 0.03436361253261566
Iteration 140, loss 2.2007925510406494, site loss 0.03686457872390747
Iteration 141, loss 2.1533095836639404, site loss 0.03292914479970932
Iteration 142, loss 2.137582778930664, site loss 0.033227816224098206
Iteration 143, loss 2.1085023880004883, site loss 0.03263767063617706
Iteration 144, loss 2.1557021141052246, site loss 0.03146440535783768
Iteration 145, loss 2.071688413619995, site loss 0.033511288464069366
Iteration 146, loss 2.0904130935668945, site loss 0.029395263642072678
Iteration 147, loss 2.1447372436523438, site loss 0.032026082277297974
Iteration 148, loss 2.151904582977295, site loss 0.03240890055894852
Iteration 149, loss 2.085878610610962, site loss 0.032649729400873184
Iteration 150, loss 2.121244192123413, site loss 0.030775493010878563
Iteration 151, loss 2.116820812225342, site loss 0.03297022730112076
Iteration 152, loss 2.107203483581543, site loss 0.03338067978620529
Iteration 153, loss 2.0973973274230957, site loss 0.03113621659576893
Iteration 154, loss 2.1352343559265137, site loss 0.030890069901943207
Iteration 155, loss 2.1551952362060547, site loss 0.03225331008434296
Iteration 156, loss 2.092766761779785, site loss 0.030146554112434387
Iteration 157, loss 2.137582302093506, site loss 0.02946648746728897
Iteration 158, loss 2.0991909503936768, site loss 0.02837122604250908
Iteration 159, loss 2.146876811981201, site loss 0.029169820249080658
Iteration 160, loss 2.1347289085388184, site loss 0.030027886852622032
Iteration 161, loss 2.054368495941162, site loss 0.02677425742149353
Iteration 162, loss 2.0780177116394043, site loss 0.031809475272893906
Iteration 163, loss 2.0049424171447754, site loss 0.027692025527358055
Iteration 164, loss 2.0856919288635254, site loss 0.029465988278388977
Iteration 165, loss 2.070885419845581, site loss 0.029142003506422043
Iteration 166, loss 2.0481090545654297, site loss 0.028643958270549774
Iteration 167, loss 2.125704288482666, site loss 0.03064125031232834
Iteration 168, loss 2.103710174560547, site loss 0.02826998382806778
Iteration 169, loss 2.1050350666046143, site loss 0.0328308567404747
Iteration 170, loss 2.0739996433258057, site loss 0.02869652397930622
Iteration 171, loss 2.106992483139038, site loss 0.029457001015543938
Iteration 172, loss 2.0990047454833984, site loss 0.030629660934209824
Iteration 173, loss 2.0669939517974854, site loss 0.028095878660678864
Iteration 174, loss 2.133343458175659, site loss 0.027898844331502914
Iteration 175, loss 2.0425429344177246, site loss 0.02788250707089901
Iteration 176, loss 2.040316343307495, site loss 0.027333345264196396
Iteration 177, loss 2.0521833896636963, site loss 0.028457868844270706
Iteration 178, loss 2.051762580871582, site loss 0.029708873480558395
Iteration 179, loss 2.0240721702575684, site loss 0.02899770811200142
Iteration 180, loss 2.055549383163452, site loss 0.026849476620554924
Iteration 181, loss 2.0789425373077393, site loss 0.02733065001666546
Iteration 182, loss 2.033677577972412, site loss 0.02596951648592949
Iteration 183, loss 2.0332088470458984, site loss 0.030750231817364693
Iteration 184, loss 2.0056722164154053, site loss 0.029304800555109978
Iteration 185, loss 2.050807237625122, site loss 0.028002187609672546
Iteration 186, loss 2.033085823059082, site loss 0.027089204639196396
Iteration 187, loss 1.9795336723327637, site loss 0.02863188460469246
Iteration 188, loss 2.05100679397583, site loss 0.02704976499080658
Iteration 189, loss 2.0025064945220947, site loss 0.026820015162229538
Iteration 190, loss 1.9626760482788086, site loss 0.024995112791657448
Iteration 191, loss 1.8729625940322876, site loss 0.026874041184782982
Iteration 192, loss 1.9447221755981445, site loss 0.02885977365076542
Iteration 193, loss 2.0051844120025635, site loss 0.02888140082359314
Iteration 194, loss 2.077775001525879, site loss 0.027047893032431602
Iteration 195, loss 2.018876791000366, site loss 0.027249639853835106
Iteration 196, loss 2.0546908378601074, site loss 0.02836599200963974
Iteration 197, loss 1.9860031604766846, site loss 0.027752231806516647
Iteration 198, loss 2.6550326347351074, site loss 0.06241016089916229
Iteration 199, loss 2.009568929672241, site loss 0.02723102644085884
Iteration 200, loss 1.9879004955291748, site loss 0.028315430507063866
Iteration 201, loss 2.0357542037963867, site loss 0.030464068055152893
Iteration 202, loss 1.9632225036621094, site loss 0.026086194440722466
Iteration 203, loss 1.9292864799499512, site loss 0.027382779866456985
Iteration 204, loss 1.9543391466140747, site loss 0.028385020792484283
Iteration 205, loss 1.9569871425628662, site loss 0.02961229719221592
Iteration 206, loss 1.947501301765442, site loss 0.0293591246008873
Iteration 207, loss 1.8912920951843262, site loss 0.024280613288283348
Iteration 208, loss 1.8973724842071533, site loss 0.025754090398550034
Iteration 209, loss 1.8910834789276123, site loss 0.025125451385974884
Iteration 210, loss 1.9126803874969482, site loss 0.026470940560102463
Iteration 211, loss 1.8868300914764404, site loss 0.027791641652584076
Iteration 212, loss 1.8996244668960571, site loss 0.02649865299463272
Iteration 213, loss 1.8406152725219727, site loss 0.026229746639728546
Iteration 214, loss 1.9163569211959839, site loss 0.025705959647893906
Iteration 215, loss 1.880859613418579, site loss 0.02337544783949852
Iteration 216, loss 1.946613073348999, site loss 0.027501670643687248
Iteration 217, loss 1.8748085498809814, site loss 0.02678963728249073
Iteration 218, loss 1.957516074180603, site loss 0.024763723835349083
Iteration 219, loss 1.9588383436203003, site loss 0.02512265369296074
Iteration 220, loss 1.9082599878311157, site loss 0.025827664881944656
Iteration 221, loss 1.9507336616516113, site loss 0.026583554223179817
Iteration 222, loss 2.0017497539520264, site loss 0.029951486736536026
Iteration 223, loss 1.9950108528137207, site loss 0.028712036088109016
Iteration 224, loss 2.0202674865722656, site loss 0.028558945283293724
Iteration 225, loss 1.9685295820236206, site loss 0.02835615910589695
Iteration 226, loss 1.9578869342803955, site loss 0.026049502193927765
Iteration 227, loss 1.9131264686584473, site loss 0.027124658226966858
Iteration 228, loss 1.9669971466064453, site loss 0.029654335230588913
Iteration 229, loss 1.909671664237976, site loss 0.027960235252976418
Iteration 230, loss 1.9132969379425049, site loss 0.02580299600958824
Iteration 231, loss 2.012996196746826, site loss 0.029882444068789482
Iteration 232, loss 1.9010467529296875, site loss 0.0291752852499485
Iteration 233, loss 2.056018829345703, site loss 0.028674695640802383
Iteration 234, loss 1.9206024408340454, site loss 0.02606179006397724
Iteration 235, loss 1.9346009492874146, site loss 0.028328780084848404
Iteration 236, loss 1.828789234161377, site loss 0.024369705468416214
Iteration 237, loss 1.8661613464355469, site loss 0.02820511721074581
Iteration 238, loss 1.8861491680145264, site loss 0.024469995871186256
Iteration 239, loss 1.870013952255249, site loss 0.027121201157569885
Iteration 240, loss 1.8365237712860107, site loss 0.026347946375608444
Iteration 241, loss 2.025672674179077, site loss 0.026819389313459396
Iteration 242, loss 1.8795093297958374, site loss 0.02558174729347229
Iteration 243, loss 1.9194557666778564, site loss 0.026117442175745964
Iteration 244, loss 1.8563768863677979, site loss 0.0273524671792984
Iteration 245, loss 1.8466987609863281, site loss 0.025723382830619812
Iteration 246, loss 1.9163727760314941, site loss 0.022939277812838554
Iteration 247, loss 1.9260210990905762, site loss 0.02625899389386177
Iteration 248, loss 1.894342303276062, site loss 0.02717011049389839
Iteration 249, loss 1.8731579780578613, site loss 0.02466733008623123
Iteration 250, loss 1.9006611108779907, site loss 0.025039438158273697
Iteration 251, loss 1.864624261856079, site loss 0.026196984574198723
Iteration 252, loss 1.9128575325012207, site loss 0.02424168586730957
Iteration 253, loss 1.887796401977539, site loss 0.02577287144958973
Iteration 254, loss 1.8020625114440918, site loss 0.02360597997903824
Iteration 255, loss 1.7791860103607178, site loss 0.023375414311885834
Iteration 256, loss 1.874043345451355, site loss 0.022805090993642807
Iteration 257, loss 1.8085744380950928, site loss 0.02372763305902481
Iteration 258, loss 1.857133150100708, site loss 0.022650958970189095
Iteration 259, loss 1.8013323545455933, site loss 0.022154945880174637
Iteration 260, loss 1.8046979904174805, site loss 0.02218138426542282
Iteration 261, loss 1.8587406873703003, site loss 0.023442436009645462
Iteration 262, loss 1.7709318399429321, site loss 0.023285187780857086
Iteration 263, loss 1.8513121604919434, site loss 0.02205764874815941
Iteration 264, loss 1.85499906539917, site loss 0.027064546942710876
Iteration 265, loss 1.764665961265564, site loss 0.02130167931318283
Iteration 266, loss 1.844355583190918, site loss 0.02177717350423336
Iteration 267, loss 1.7744879722595215, site loss 0.02091386169195175
Iteration 268, loss 1.8269686698913574, site loss 0.025281168520450592
Iteration 269, loss 1.7968733310699463, site loss 0.024510521441698074
Iteration 270, loss 1.881792664527893, site loss 0.02271396294236183
Iteration 271, loss 1.8142492771148682, site loss 0.023789871484041214
Iteration 272, loss 1.9022448062896729, site loss 0.025231458246707916
Iteration 273, loss 1.8305740356445312, site loss 0.026156719774007797
Iteration 274, loss 1.7883877754211426, site loss 0.0214582160115242
Iteration 275, loss 1.8898463249206543, site loss 0.02250346727669239
Iteration 276, loss 1.7811229228973389, site loss 0.019904635846614838
Iteration 277, loss 1.75443696975708, site loss 0.023372191935777664
Iteration 278, loss 1.8568638563156128, site loss 0.019844897091388702
Iteration 279, loss 1.7643980979919434, site loss 0.019148193299770355
Iteration 280, loss 1.806020736694336, site loss 0.021960459649562836
Iteration 281, loss 1.8480384349822998, site loss 0.02253386378288269
Iteration 282, loss 1.8691377639770508, site loss 0.025160618126392365
Iteration 283, loss 1.8164000511169434, site loss 0.021908661350607872
Iteration 284, loss 1.855643630027771, site loss 0.020972371101379395
Iteration 285, loss 1.8276383876800537, site loss 0.023368490859866142
Iteration 286, loss 1.7788465023040771, site loss 0.020222507417201996
Iteration 287, loss 1.820244312286377, site loss 0.021299127489328384
Iteration 288, loss 1.8592369556427002, site loss 0.02317476086318493
Iteration 289, loss 1.7711758613586426, site loss 0.022532794624567032
Iteration 290, loss 1.7450072765350342, site loss 0.019520167261362076
Iteration 291, loss 1.7725157737731934, site loss 0.022905543446540833
Iteration 292, loss 1.838979959487915, site loss 0.021355291828513145
Iteration 293, loss 1.7866144180297852, site loss 0.02182304859161377
Iteration 294, loss 1.8187143802642822, site loss 0.023511871695518494
Iteration 295, loss 1.7783023118972778, site loss 0.02047157846391201
Iteration 296, loss 1.858430027961731, site loss 0.021999508142471313
Iteration 297, loss 1.7766838073730469, site loss 0.021797873079776764
Iteration 298, loss 1.7900416851043701, site loss 0.020978514105081558
Iteration 299, loss 1.9095706939697266, site loss 0.0247972309589386
Iteration 300, loss 1.756327509880066, site loss 0.020335335284471512
Iteration 301, loss 1.8474239110946655, site loss 0.02343066595494747
Iteration 302, loss 1.7703239917755127, site loss 0.022828184068202972
Iteration 303, loss 1.7895991802215576, site loss 0.02187095768749714
Iteration 304, loss 1.7599389553070068, site loss 0.02215539664030075
Iteration 305, loss 1.7702330350875854, site loss 0.01914469711482525
Iteration 306, loss 1.794245719909668, site loss 0.0211520753800869
Iteration 307, loss 1.8437223434448242, site loss 0.021938439458608627
Iteration 308, loss 1.8103618621826172, site loss 0.020621202886104584
Iteration 309, loss 1.7887802124023438, site loss 0.022310009226202965
Iteration 310, loss 1.7406853437423706, site loss 0.018976151943206787
Iteration 311, loss 1.757123351097107, site loss 0.019695844501256943
Iteration 312, loss 1.7948147058486938, site loss 0.020514776930212975
Iteration 313, loss 1.8488762378692627, site loss 0.02571544423699379
Iteration 314, loss 2.4027764797210693, site loss 0.052458811551332474
Iteration 315, loss 1.7423714399337769, site loss 0.019071105867624283
Iteration 316, loss 1.7923418283462524, site loss 0.019126510247588158
Iteration 317, loss 1.784006953239441, site loss 0.020161183550953865
Iteration 318, loss 1.7893155813217163, site loss 0.019535481929779053
Iteration 319, loss 1.8072713613510132, site loss 0.019023993983864784
Iteration 320, loss 1.793252944946289, site loss 0.0213914904743433
Iteration 321, loss 1.7831087112426758, site loss 0.018743116408586502
Iteration 322, loss 1.75668466091156, site loss 0.01712905988097191
Iteration 323, loss 1.744788646697998, site loss 0.020950060337781906
Iteration 324, loss 1.7369709014892578, site loss 0.01957813650369644
Iteration 325, loss 1.805431842803955, site loss 0.021223159506917
Iteration 326, loss 1.8179123401641846, site loss 0.019585933536291122
Iteration 327, loss 1.7443838119506836, site loss 0.01922605186700821
Iteration 328, loss 1.73432457447052, site loss 0.016839027404785156
Iteration 329, loss 1.8415356874465942, site loss 0.021161865442991257
Iteration 330, loss 1.8192591667175293, site loss 0.018696032464504242
Iteration 331, loss 1.7686710357666016, site loss 0.019373619928956032
Iteration 332, loss 1.7583142518997192, site loss 0.02076103165745735
Iteration 333, loss 1.8091797828674316, site loss 0.018583228811621666
Iteration 334, loss 1.8236732482910156, site loss 0.018611738458275795
Iteration 335, loss 1.8309764862060547, site loss 0.019738297909498215
Iteration 336, loss 1.7436387538909912, site loss 0.019105136394500732
Iteration 337, loss 1.7138246297836304, site loss 0.01995648257434368
Iteration 338, loss 1.7286739349365234, site loss 0.020486600697040558
Iteration 339, loss 1.7822285890579224, site loss 0.020107610151171684
Iteration 340, loss 1.6567704677581787, site loss 0.016377486288547516
Iteration 341, loss 1.703965187072754, site loss 0.019623933359980583
Iteration 342, loss 1.7952200174331665, site loss 0.01819395273923874
Iteration 343, loss 1.703267216682434, site loss 0.01543545164167881
Iteration 344, loss 1.8005892038345337, site loss 0.019177716225385666
Iteration 345, loss 1.6877515316009521, site loss 0.017453469336032867
Iteration 346, loss 1.7890610694885254, site loss 0.017806869000196457
Iteration 347, loss 1.7468109130859375, site loss 0.01799987070262432
Iteration 348, loss 1.731478214263916, site loss 0.016569584608078003
Iteration 349, loss 1.757495403289795, site loss 0.016378307715058327
Iteration 350, loss 1.6591635942459106, site loss 0.016921214759349823
Iteration 351, loss 1.7485041618347168, site loss 0.01627945899963379
Iteration 352, loss 1.7541049718856812, site loss 0.016192955896258354
Iteration 353, loss 1.7149410247802734, site loss 0.014832626096904278
Iteration 354, loss 1.7725845575332642, site loss 0.016128720715641975
Iteration 355, loss 1.7348164319992065, site loss 0.016600824892520905
Iteration 356, loss 1.693455696105957, site loss 0.017533939331769943
Iteration 357, loss 1.672642469406128, site loss 0.017151523381471634
Iteration 358, loss 1.7712297439575195, site loss 0.017101403325796127
Iteration 359, loss 1.7493294477462769, site loss 0.01669778674840927
Iteration 360, loss 1.7536439895629883, site loss 0.01876462996006012
Iteration 361, loss 1.689546823501587, site loss 0.01623527519404888
Iteration 362, loss 1.6607751846313477, site loss 0.014832220040261745
Iteration 363, loss 1.6649583578109741, site loss 0.016118532046675682
Iteration 364, loss 1.7716100215911865, site loss 0.016516339033842087
Iteration 365, loss 1.7376126050949097, site loss 0.017365366220474243
Iteration 366, loss 1.67140531539917, site loss 0.01619873009622097
Iteration 367, loss 1.6318633556365967, site loss 0.016837310045957565
Iteration 368, loss 1.763321876525879, site loss 0.014849994331598282
Iteration 369, loss 1.688460111618042, site loss 0.018154585734009743
Iteration 370, loss 1.6312382221221924, site loss 0.015047332271933556
Iteration 371, loss 1.6708186864852905, site loss 0.015234420076012611
Iteration 372, loss 1.7324272394180298, site loss 0.018925733864307404
Iteration 373, loss 1.6704473495483398, site loss 0.016912344843149185
Iteration 374, loss 1.6697957515716553, site loss 0.015313029289245605
Iteration 375, loss 1.736274242401123, site loss 0.020199358463287354
Iteration 376, loss 1.7339180707931519, site loss 0.01608137972652912
Iteration 377, loss 1.7363991737365723, site loss 0.018131814897060394
Iteration 378, loss 1.7412455081939697, site loss 0.017123600468039513
Iteration 379, loss 1.6551285982131958, site loss 0.017765827476978302
Iteration 380, loss 1.721895694732666, site loss 0.01612146943807602
Iteration 381, loss 1.7736952304840088, site loss 0.01777317188680172
Iteration 382, loss 1.6273375749588013, site loss 0.015451779589056969
Iteration 383, loss 1.7600553035736084, site loss 0.018683161586523056
Iteration 384, loss 1.6437182426452637, site loss 0.01363813690841198
Iteration 385, loss 1.6615889072418213, site loss 0.015403583645820618
Iteration 386, loss 1.6826488971710205, site loss 0.016606727614998817
Iteration 387, loss 1.7669185400009155, site loss 0.01671670749783516
Iteration 388, loss 1.7737157344818115, site loss 0.01731499284505844
Iteration 389, loss 1.8093369007110596, site loss 0.018299497663974762
Iteration 390, loss 1.71246337890625, site loss 0.018160689622163773
Iteration 391, loss 1.8424590826034546, site loss 0.01732444018125534
Iteration 392, loss 1.7254936695098877, site loss 0.01920030266046524
Iteration 393, loss 1.7174983024597168, site loss 0.019376464188098907
Iteration 394, loss 1.7369329929351807, site loss 0.0199324581772089
Iteration 395, loss 1.69248628616333, site loss 0.016208171844482422
Iteration 396, loss 1.7119057178497314, site loss 0.017175013199448586
Iteration 397, loss 1.7298250198364258, site loss 0.018847398459911346
Iteration 398, loss 2.172257423400879, site loss 0.03114902600646019
Iteration 399, loss 1.7060141563415527, site loss 0.0197739414870739
Iteration 400, loss 1.6797363758087158, site loss 0.017024647444486618
Iteration 401, loss 1.6597188711166382, site loss 0.019470028579235077
Iteration 402, loss 1.7041447162628174, site loss 0.016735469922423363
Iteration 403, loss 1.7029128074645996, site loss 0.019916173070669174
Iteration 404, loss 1.6034390926361084, site loss 0.015006366185843945
Iteration 405, loss 1.7318158149719238, site loss 0.016915805637836456
Iteration 406, loss 1.662611484527588, site loss 0.01368116308003664
Iteration 407, loss 1.684828758239746, site loss 0.01588129624724388
Iteration 408, loss 1.5253418684005737, site loss 0.014018569141626358
Iteration 409, loss 1.710247278213501, site loss 0.016971727833151817
Iteration 410, loss 1.5784012079238892, site loss 0.014854157343506813
Iteration 411, loss 1.6474859714508057, site loss 0.01650632917881012
Iteration 412, loss 1.6758869886398315, site loss 0.013854622840881348
Iteration 413, loss 1.652744174003601, site loss 0.016917649656534195
Iteration 414, loss 1.5599143505096436, site loss 0.01481698639690876
Iteration 415, loss 1.6988048553466797, site loss 0.017487749457359314
Iteration 416, loss 1.6646499633789062, site loss 0.017854854464530945
Iteration 417, loss 1.6339800357818604, site loss 0.017042050138115883
Iteration 418, loss 1.6718971729278564, site loss 0.016438839957118034
Iteration 419, loss 1.564529299736023, site loss 0.014205094426870346
Iteration 420, loss 1.5991647243499756, site loss 0.015225574374198914
Iteration 421, loss 1.5947678089141846, site loss 0.013780826702713966
Iteration 422, loss 1.671830177307129, site loss 0.015377303585410118
Iteration 423, loss 1.5999656915664673, site loss 0.014905039221048355
Iteration 424, loss 1.541363000869751, site loss 0.014183090068399906
Iteration 425, loss 1.5872611999511719, site loss 0.01570989564061165
Iteration 426, loss 1.6350789070129395, site loss 0.015751603990793228
Iteration 427, loss 1.5513267517089844, site loss 0.013760518282651901
Iteration 428, loss 1.6656396389007568, site loss 0.01674223691225052
Iteration 429, loss 1.6065902709960938, site loss 0.017850201576948166
Iteration 430, loss 1.705540657043457, site loss 0.015633882954716682
Iteration 431, loss 1.6191635131835938, site loss 0.017471294850111008
Iteration 432, loss 1.534333348274231, site loss 0.015657732263207436
Iteration 433, loss 1.5645631551742554, site loss 0.014811903238296509
Iteration 434, loss 1.6195905208587646, site loss 0.015077777206897736
Iteration 435, loss 1.5222253799438477, site loss 0.016108248382806778
Iteration 436, loss 1.6327500343322754, site loss 0.014894478023052216
Iteration 437, loss 1.554680347442627, site loss 0.0154347475618124
Iteration 438, loss 1.51361882686615, site loss 0.01507088728249073
Iteration 439, loss 1.5529141426086426, site loss 0.015221834182739258
Iteration 440, loss 1.6823577880859375, site loss 0.017015717923641205
Iteration 441, loss 1.5326199531555176, site loss 0.013628346845507622
Iteration 442, loss 1.5530003309249878, site loss 0.012802178040146828
Iteration 443, loss 1.5795862674713135, site loss 0.014419309794902802
Iteration 444, loss 1.6322575807571411, site loss 0.015239539556205273
Iteration 445, loss 1.6082916259765625, site loss 0.014300067909061909
Iteration 446, loss 1.6109187602996826, site loss 0.013345155864953995
Iteration 447, loss 1.5584418773651123, site loss 0.015097914263606071
Iteration 448, loss 1.5586178302764893, site loss 0.015393584966659546
Iteration 449, loss 1.575317621231079, site loss 0.013703517615795135
Iteration 450, loss 1.5829663276672363, site loss 0.016033442690968513
Iteration 451, loss 1.5380576848983765, site loss 0.013559069484472275
Iteration 452, loss 1.59274160861969, site loss 0.01451382040977478
Iteration 453, loss 1.5387954711914062, site loss 0.01410579215735197
Iteration 454, loss 1.6386079788208008, site loss 0.012954385951161385
Iteration 455, loss 1.6257808208465576, site loss 0.015599243342876434
Iteration 456, loss 1.5809293985366821, site loss 0.01679982990026474
Iteration 457, loss 1.588779091835022, site loss 0.012634480372071266
Iteration 458, loss 1.629140019416809, site loss 0.01593107171356678
Iteration 459, loss 1.4496852159500122, site loss 0.012173295021057129
Iteration 460, loss 1.5613369941711426, site loss 0.013772796839475632
Iteration 461, loss 1.584014892578125, site loss 0.01599261537194252
Iteration 462, loss 1.5436818599700928, site loss 0.014286593534052372
Iteration 463, loss 1.5845204591751099, site loss 0.01392335258424282
Iteration 464, loss 1.5327513217926025, site loss 0.013334045186638832
Iteration 465, loss 1.5889829397201538, site loss 0.013243784196674824
Iteration 466, loss 1.556900143623352, site loss 0.014022675342857838
Iteration 467, loss 1.57852303981781, site loss 0.011486109346151352
Iteration 468, loss 1.5275822877883911, site loss 0.013126190751791
Iteration 469, loss 1.4560344219207764, site loss 0.013717991299927235
Iteration 470, loss 1.5986416339874268, site loss 0.01724570244550705
Iteration 471, loss 1.530667781829834, site loss 0.012661430984735489
Iteration 472, loss 1.5464956760406494, site loss 0.012958399951457977
Iteration 473, loss 1.5283558368682861, site loss 0.014124397188425064
Iteration 474, loss 1.5482850074768066, site loss 0.013698206283152103
Iteration 475, loss 1.585404634475708, site loss 0.01535532996058464
Iteration 476, loss 1.5253345966339111, site loss 0.01361186895519495
Iteration 477, loss 1.5563669204711914, site loss 0.015617064200341702
Iteration 478, loss 1.4783258438110352, site loss 0.014080476015806198
Iteration 479, loss 1.511372447013855, site loss 0.01409426610916853
Iteration 480, loss 1.476640224456787, site loss 0.012479349039494991
Iteration 481, loss 1.551206111907959, site loss 0.013582483865320683
Iteration 482, loss 1.4855365753173828, site loss 0.013221788220107555
Iteration 483, loss 1.5419998168945312, site loss 0.012419227510690689
Iteration 484, loss 1.566408395767212, site loss 0.013189489021897316
Iteration 485, loss 1.558435320854187, site loss 0.014716973528265953
Iteration 486, loss 1.4957526922225952, site loss 0.012953408993780613
Iteration 487, loss 1.6226590871810913, site loss 0.013947810046374798
Iteration 488, loss 1.5208404064178467, site loss 0.013050666078925133
Iteration 489, loss 1.5237455368041992, site loss 0.013368560932576656
Iteration 490, loss 1.5483019351959229, site loss 0.014860434457659721
Iteration 491, loss 1.5934207439422607, site loss 0.01499426644295454
Iteration 492, loss 1.6303315162658691, site loss 0.016264447942376137
Iteration 493, loss 1.513427495956421, site loss 0.012698723003268242
Iteration 494, loss 1.5166795253753662, site loss 0.013071219436824322
Iteration 495, loss 1.4675076007843018, site loss 0.012791842222213745
Iteration 496, loss 1.571855068206787, site loss 0.013425114564597607
Iteration 497, loss 1.5041658878326416, site loss 0.012421633116900921
Iteration 498, loss 1.503817081451416, site loss 0.014132300391793251
Iteration 499, loss 1.5666691064834595, site loss 0.014533092267811298
Iteration 500, loss 1.5945959091186523, site loss 0.01437065564095974
Iteration 501, loss 1.5529122352600098, site loss 0.014914745464920998
Iteration 502, loss 1.527382254600525, site loss 0.014818241819739342
Iteration 503, loss 1.523226261138916, site loss 0.013380037620663643
Iteration 504, loss 1.5201096534729004, site loss 0.01336205005645752
Iteration 505, loss 1.5662269592285156, site loss 0.0158137995749712
Iteration 506, loss 1.4975371360778809, site loss 0.012558511458337307
Iteration 507, loss 1.500250220298767, site loss 0.013298201374709606
Iteration 508, loss 1.4566059112548828, site loss 0.012064505368471146
Iteration 509, loss 1.49702787399292, site loss 0.011816934682428837
Iteration 510, loss 1.5468249320983887, site loss 0.015093762427568436
Iteration 511, loss 1.5676846504211426, site loss 0.012771031819283962
Iteration 512, loss 1.5323114395141602, site loss 0.012409595772624016
Iteration 513, loss 1.5740275382995605, site loss 0.014407421462237835
Iteration 514, loss 1.4654834270477295, site loss 0.011208311654627323
Iteration 515, loss 1.5365397930145264, site loss 0.013697518967092037
Iteration 516, loss 1.500580906867981, site loss 0.01279476284980774
Iteration 517, loss 1.4789512157440186, site loss 0.01137887965887785
Iteration 518, loss 1.6431162357330322, site loss 0.013876786455512047
Iteration 519, loss 1.5342004299163818, site loss 0.011732031591236591
Iteration 520, loss 1.6214392185211182, site loss 0.014727502129971981
Iteration 521, loss 1.4383963346481323, site loss 0.011709264479577541
Iteration 522, loss 1.5396791696548462, site loss 0.010852394625544548
Iteration 523, loss 1.5631850957870483, site loss 0.014077616855502129
Iteration 524, loss 1.4083149433135986, site loss 0.010777882300317287
Iteration 525, loss 1.4395569562911987, site loss 0.011490552686154842
Iteration 526, loss 1.4970524311065674, site loss 0.010456908494234085
Iteration 527, loss 1.610320806503296, site loss 0.0144888274371624
Iteration 528, loss 2.050973653793335, site loss 0.026969294995069504
Iteration 529, loss 1.489893913269043, site loss 0.01057093683630228
Iteration 530, loss 1.613222599029541, site loss 0.012614049017429352
Iteration 531, loss 1.5534429550170898, site loss 0.011171378195285797
Iteration 532, loss 1.5878064632415771, site loss 0.016029225662350655
Iteration 533, loss 1.4710248708724976, site loss 0.01072452962398529
Iteration 534, loss 1.5689163208007812, site loss 0.013260467909276485
Iteration 535, loss 1.5535917282104492, site loss 0.013454957865178585
Iteration 536, loss 1.5054028034210205, site loss 0.010380666702985764
Iteration 537, loss 1.4546023607254028, site loss 0.012205404229462147
Iteration 538, loss 1.4930750131607056, site loss 0.012305580079555511
Iteration 539, loss 1.4833674430847168, site loss 0.010294681414961815
Iteration 540, loss 1.5431938171386719, site loss 0.01491826493293047
Iteration 541, loss 1.4663485288619995, site loss 0.012531206011772156
Iteration 542, loss 1.5593764781951904, site loss 0.014886543154716492
Iteration 543, loss 1.564610481262207, site loss 0.01095661148428917
Iteration 544, loss 1.527665615081787, site loss 0.011081874370574951
Iteration 545, loss 1.5643398761749268, site loss 0.014157060533761978
Iteration 546, loss 1.6213974952697754, site loss 0.014163060113787651
Iteration 547, loss 1.5374720096588135, site loss 0.013057250529527664
Iteration 548, loss 1.4704395532608032, site loss 0.013963286764919758
Iteration 549, loss 1.5170094966888428, site loss 0.012280160561203957
Iteration 550, loss 1.4938437938690186, site loss 0.011133546009659767
Iteration 551, loss 1.52543306350708, site loss 0.012010732665657997
Iteration 552, loss 1.5958588123321533, site loss 0.011428192257881165
Iteration 553, loss 1.5059720277786255, site loss 0.01178915984928608
Iteration 554, loss 1.5084600448608398, site loss 0.012430725619196892
Iteration 555, loss 1.5614013671875, site loss 0.012325886636972427
Iteration 556, loss 1.4819190502166748, site loss 0.011977089568972588
Iteration 557, loss 1.5797038078308105, site loss 0.0134504409506917
Iteration 558, loss 1.5185624361038208, site loss 0.011445067822933197
Iteration 559, loss 1.5240592956542969, site loss 0.013688859529793262
Iteration 560, loss 1.5138427019119263, site loss 0.01122397929430008
Iteration 561, loss 1.459789514541626, site loss 0.011213259771466255
Iteration 562, loss 1.5276358127593994, site loss 0.012339827604591846
Iteration 563, loss 1.50893235206604, site loss 0.014567200094461441
Iteration 564, loss 1.4518170356750488, site loss 0.009687012061476707
Iteration 565, loss 1.5208847522735596, site loss 0.010453084483742714
Iteration 566, loss 1.5444200038909912, site loss 0.011331995949149132
Iteration 567, loss 1.4954910278320312, site loss 0.01318817213177681
Iteration 568, loss 1.4410039186477661, site loss 0.01184301357716322
Iteration 569, loss 1.4768340587615967, site loss 0.012242123484611511
Iteration 570, loss 1.4339516162872314, site loss 0.010438818484544754
Iteration 571, loss 1.4682815074920654, site loss 0.011451777070760727
Iteration 572, loss 1.6166661977767944, site loss 0.013408319093286991
Iteration 573, loss 1.4804397821426392, site loss 0.011126717552542686
Iteration 574, loss 1.5118368864059448, site loss 0.012490751221776009
Iteration 575, loss 1.387769341468811, site loss 0.008750274777412415
Iteration 576, loss 1.4694912433624268, site loss 0.012362858280539513
Iteration 577, loss 1.5026154518127441, site loss 0.011103502474725246
Iteration 578, loss 1.4075870513916016, site loss 0.009952245280146599
Iteration 579, loss 1.5066722631454468, site loss 0.012762537226080894
Iteration 580, loss 1.5039231777191162, site loss 0.012069983407855034
Iteration 581, loss 1.4586145877838135, site loss 0.010913129895925522
Iteration 582, loss 1.5864031314849854, site loss 0.0148667823523283
Iteration 583, loss 1.5147254467010498, site loss 0.01377855148166418
Iteration 584, loss 1.5082778930664062, site loss 0.014054364524781704
Iteration 585, loss 1.3668702840805054, site loss 0.012477772310376167
Iteration 586, loss 1.617572546005249, site loss 0.015204066410660744
Iteration 587, loss 1.609200358390808, site loss 0.015688197687268257
Iteration 588, loss 1.5839025974273682, site loss 0.01487930677831173
Iteration 589, loss 1.6098685264587402, site loss 0.013745521195232868
Iteration 590, loss 1.4454138278961182, site loss 0.014535868540406227
Iteration 591, loss 1.5390737056732178, site loss 0.01587427780032158
Iteration 592, loss 1.4886701107025146, site loss 0.010972613468766212
Iteration 593, loss 1.5789976119995117, site loss 0.013000713661313057
Iteration 594, loss 1.430856704711914, site loss 0.013298993930220604
Iteration 595, loss 1.5471757650375366, site loss 0.012571482919156551
Iteration 596, loss 1.4729688167572021, site loss 0.011798443272709846
Iteration 597, loss 1.5619869232177734, site loss 0.013896401971578598
Iteration 598, loss 1.5196306705474854, site loss 0.015482808463275433
Iteration 599, loss 1.4353556632995605, site loss 0.012027168646454811
Iteration 600, loss 1.4516644477844238, site loss 0.012427957728505135
Iteration 601, loss 1.5153934955596924, site loss 0.013437449000775814
Iteration 602, loss 1.5311423540115356, site loss 0.014242468401789665
Iteration 603, loss 1.7326364517211914, site loss 0.024144992232322693
Iteration 604, loss 1.4949610233306885, site loss 0.011722862720489502
Iteration 605, loss 1.4910690784454346, site loss 0.01083904318511486
Iteration 606, loss 1.5249263048171997, site loss 0.012917635962367058
Iteration 607, loss 1.4794032573699951, site loss 0.012283973395824432
Iteration 608, loss 1.5117666721343994, site loss 0.011501490138471127
Iteration 609, loss 1.4429099559783936, site loss 0.011867941357195377
Iteration 610, loss 1.4671721458435059, site loss 0.013125763274729252
Iteration 611, loss 1.5053342580795288, site loss 0.013748925179243088
Iteration 612, loss 1.4832191467285156, site loss 0.013177495449781418
Iteration 613, loss 1.5026105642318726, site loss 0.011650847271084785
Iteration 614, loss 1.3849906921386719, site loss 0.010703053325414658
Iteration 615, loss 1.4172189235687256, site loss 0.01038576103746891
Iteration 616, loss 1.4194912910461426, site loss 0.012686758302152157
Iteration 617, loss 1.473502516746521, site loss 0.01338893547654152
Iteration 618, loss 1.4443228244781494, site loss 0.011525765061378479
Iteration 619, loss 1.4665334224700928, site loss 0.010639417916536331
Iteration 620, loss 1.5009047985076904, site loss 0.013168334029614925
Iteration 621, loss 1.4477481842041016, site loss 0.012133472599089146
Iteration 622, loss 1.421017050743103, site loss 0.012695717625319958
Iteration 623, loss 1.4914411306381226, site loss 0.011655285954475403
Iteration 624, loss 1.3645234107971191, site loss 0.010522869415581226
Iteration 625, loss 1.400038719177246, site loss 0.009222413413226604
Iteration 626, loss 1.365039587020874, site loss 0.010969136841595173
Iteration 627, loss 1.3444879055023193, site loss 0.012123850174248219
Iteration 628, loss 1.441774845123291, site loss 0.012325507588684559
Iteration 629, loss 1.4273788928985596, site loss 0.010644393041729927
Iteration 630, loss 1.3004984855651855, site loss 0.00966392271220684
Iteration 631, loss 1.4220317602157593, site loss 0.010671088472008705
Iteration 632, loss 1.533711552619934, site loss 0.01249644998461008
Iteration 633, loss 1.459895133972168, site loss 0.0129800233989954
Iteration 634, loss 1.396146535873413, site loss 0.010909954085946083
Iteration 635, loss 1.4776077270507812, site loss 0.010794186033308506
Iteration 636, loss 1.366508960723877, site loss 0.012897287495434284
Iteration 637, loss 1.4892505407333374, site loss 0.014680958352982998
Iteration 638, loss 1.505130410194397, site loss 0.01220276951789856
Iteration 639, loss 1.4990710020065308, site loss 0.012517508119344711
Iteration 640, loss 1.3907206058502197, site loss 0.010826705023646355
Iteration 641, loss 1.454023003578186, site loss 0.010863362811505795
Iteration 642, loss 1.3359291553497314, site loss 0.010271322913467884
Iteration 643, loss 1.4076447486877441, site loss 0.01318872720003128
Iteration 644, loss 1.3784373998641968, site loss 0.01089393813163042
Iteration 645, loss 1.502664566040039, site loss 0.012745125219225883
Iteration 646, loss 1.3620924949645996, site loss 0.01055192667990923
Iteration 647, loss 1.390322208404541, site loss 0.011829040944576263
Iteration 648, loss 1.3323360681533813, site loss 0.009876050986349583
Iteration 649, loss 1.2966512441635132, site loss 0.00992382038384676
Iteration 650, loss 1.3371989727020264, site loss 0.009069947525858879
Iteration 651, loss 1.3286404609680176, site loss 0.011886036023497581
Iteration 652, loss 1.3629430532455444, site loss 0.008889209479093552
Iteration 653, loss 1.372118592262268, site loss 0.01114281639456749
Iteration 654, loss 1.396583080291748, site loss 0.010879553854465485
Iteration 655, loss 1.4595425128936768, site loss 0.011671405285596848
Iteration 656, loss 1.3224725723266602, site loss 0.010380281135439873
Iteration 657, loss 1.388307809829712, site loss 0.01031755656003952
Iteration 658, loss 1.4318428039550781, site loss 0.012233487330377102
Iteration 659, loss 1.3203803300857544, site loss 0.010576512664556503
Iteration 660, loss 1.370463252067566, site loss 0.010969426482915878
Iteration 661, loss 1.4983899593353271, site loss 0.012168152257800102
Iteration 662, loss 1.368729829788208, site loss 0.008788179606199265
Iteration 663, loss 1.3911781311035156, site loss 0.011361408047378063
Iteration 664, loss 1.390561819076538, site loss 0.011530487798154354
Iteration 665, loss 1.3547093868255615, site loss 0.010074082762002945
Iteration 666, loss 1.3544433116912842, site loss 0.009301758371293545
Iteration 667, loss 1.4387221336364746, site loss 0.011221285909414291
Iteration 668, loss 1.453904151916504, site loss 0.011128684505820274
Iteration 669, loss 1.5119068622589111, site loss 0.011630190536379814
Iteration 670, loss 1.271444320678711, site loss 0.007539997808635235
Iteration 671, loss 1.3259029388427734, site loss 0.010540129616856575
Iteration 672, loss 1.4293053150177002, site loss 0.009079962968826294
Iteration 673, loss 1.362278699874878, site loss 0.00993201695382595
Iteration 674, loss 1.4929826259613037, site loss 0.013636711984872818
Iteration 675, loss 1.4704936742782593, site loss 0.011815061792731285
Iteration 676, loss 1.3773744106292725, site loss 0.010666187852621078
Iteration 677, loss 1.383314847946167, site loss 0.011523742228746414
Iteration 678, loss 1.469087839126587, site loss 0.01258087158203125
Iteration 679, loss 1.3749816417694092, site loss 0.010431785136461258
Iteration 680, loss 1.430341124534607, site loss 0.010011754930019379
Iteration 681, loss 1.3701035976409912, site loss 0.009799649938941002
Iteration 682, loss 1.3130145072937012, site loss 0.008720380254089832
Iteration 683, loss 1.3057732582092285, site loss 0.010812412947416306
Iteration 684, loss 1.3668997287750244, site loss 0.010621529072523117
Iteration 685, loss 1.2801507711410522, site loss 0.00828290730714798
Iteration 686, loss 1.3297348022460938, site loss 0.010271227918565273
Iteration 687, loss 1.4426448345184326, site loss 0.013471949845552444
Iteration 688, loss 1.3524279594421387, site loss 0.009146486409008503
Iteration 689, loss 1.2708377838134766, site loss 0.008999830111861229
Iteration 690, loss 1.370274305343628, site loss 0.009183107875287533
Iteration 691, loss 1.3311200141906738, site loss 0.009790308773517609
Iteration 692, loss 1.4384621381759644, site loss 0.01225198246538639
Iteration 693, loss 1.4477877616882324, site loss 0.010134408250451088
Iteration 694, loss 1.4311723709106445, site loss 0.010063054040074348
Iteration 695, loss 1.3563213348388672, site loss 0.011465964838862419
Iteration 696, loss 1.4337979555130005, site loss 0.011935750022530556
Iteration 697, loss 1.306368350982666, site loss 0.010225861333310604
Iteration 698, loss 1.4460453987121582, site loss 0.010713573545217514
Iteration 699, loss 1.350950837135315, site loss 0.010136264376342297
Iteration 700, loss 1.3310985565185547, site loss 0.00942993350327015
Iteration 701, loss 1.31939697265625, site loss 0.009833134710788727
Iteration 702, loss 1.4488575458526611, site loss 0.010198920033872128
Iteration 703, loss 1.379172921180725, site loss 0.009744472801685333
Iteration 704, loss 1.4022458791732788, site loss 0.010952007956802845
Iteration 705, loss 1.3752024173736572, site loss 0.012179483659565449
Iteration 706, loss 1.3658559322357178, site loss 0.010385210625827312
Iteration 707, loss 1.346393346786499, site loss 0.009546713903546333
Iteration 708, loss 1.454606533050537, site loss 0.010615695267915726
Iteration 709, loss 1.487618088722229, site loss 0.012370627373456955
Iteration 710, loss 1.3040673732757568, site loss 0.007802014239132404
Iteration 711, loss 1.3725643157958984, site loss 0.009256443940103054
Iteration 712, loss 1.2634650468826294, site loss 0.008534330874681473
Iteration 713, loss 1.447094440460205, site loss 0.011505055241286755
Iteration 714, loss 1.3792243003845215, site loss 0.010577268898487091
Iteration 715, loss 1.3619959354400635, site loss 0.008855592459440231
Iteration 716, loss 1.396672010421753, site loss 0.009113788604736328
Iteration 717, loss 1.3872641324996948, site loss 0.008377470076084137
Iteration 718, loss 1.4071884155273438, site loss 0.008955582976341248
Iteration 719, loss 1.3363431692123413, site loss 0.010539274662733078
Iteration 720, loss 1.3609240055084229, site loss 0.011739225126802921
Iteration 721, loss 1.4426822662353516, site loss 0.011756514199078083
Iteration 722, loss 1.3923317193984985, site loss 0.008731241337954998
Iteration 723, loss 1.3806989192962646, site loss 0.009913649410009384
Iteration 724, loss 1.3716342449188232, site loss 0.010587209835648537
Iteration 725, loss 1.4220889806747437, site loss 0.011216709390282631
Iteration 726, loss 1.3397777080535889, site loss 0.008696887642145157
Iteration 727, loss 1.3306267261505127, site loss 0.009288011118769646
Iteration 728, loss 1.3031572103500366, site loss 0.010184340178966522
Iteration 729, loss 1.3945262432098389, site loss 0.010920235887169838
Iteration 730, loss 1.7291269302368164, site loss 0.0215580053627491
Iteration 731, loss 1.4719874858856201, site loss 0.012316163629293442
Iteration 732, loss 1.3431391716003418, site loss 0.008221251890063286
Iteration 733, loss 1.405141830444336, site loss 0.008852713741362095
Iteration 734, loss 1.3342127799987793, site loss 0.009434058330953121
Iteration 735, loss 1.4167003631591797, site loss 0.011369390413165092
Iteration 736, loss 1.4286515712738037, site loss 0.008724192157387733
Iteration 737, loss 1.346021056175232, site loss 0.00828712061047554
Iteration 738, loss 1.4650819301605225, site loss 0.010438023135066032
Iteration 739, loss 1.4104111194610596, site loss 0.010352272540330887
Iteration 740, loss 1.4837610721588135, site loss 0.009860510006546974
Iteration 741, loss 1.3334143161773682, site loss 0.011013215407729149
Iteration 742, loss 1.4772889614105225, site loss 0.010624872520565987
Iteration 743, loss 1.4084398746490479, site loss 0.012044009752571583
Iteration 744, loss 1.4798941612243652, site loss 0.012692149728536606
Iteration 745, loss 1.3386390209197998, site loss 0.008733045309782028
Iteration 746, loss 1.3725619316101074, site loss 0.0106786098331213
Iteration 747, loss 1.4093058109283447, site loss 0.01100714597851038
Iteration 748, loss 1.418421745300293, site loss 0.009092377498745918
Iteration 749, loss 1.452726125717163, site loss 0.00988508015871048
Iteration 750, loss 1.391749620437622, site loss 0.01249382458627224
Iteration 751, loss 1.4713804721832275, site loss 0.01018388383090496
Iteration 752, loss 1.3293049335479736, site loss 0.009109577164053917
Iteration 753, loss 1.3097548484802246, site loss 0.008690796792507172
Iteration 754, loss 1.3532390594482422, site loss 0.008893158286809921
Iteration 755, loss 1.3625130653381348, site loss 0.010078676044940948
Iteration 756, loss 1.3527458906173706, site loss 0.008469557389616966
Iteration 757, loss 1.513113021850586, site loss 0.011259586550295353
Iteration 758, loss 1.391305685043335, site loss 0.008230751380324364
Iteration 759, loss 1.3566489219665527, site loss 0.009158655069768429
Iteration 760, loss 1.410813570022583, site loss 0.00956285186111927
Iteration 761, loss 1.4194118976593018, site loss 0.009902944788336754
Iteration 762, loss 1.3494131565093994, site loss 0.008898017928004265
Iteration 763, loss 1.3583542108535767, site loss 0.0094688655808568
Iteration 764, loss 1.3914008140563965, site loss 0.009462995454668999
Iteration 765, loss 1.3226358890533447, site loss 0.008099241182208061
Iteration 766, loss 1.3816009759902954, site loss 0.009193909354507923
Iteration 767, loss 1.4613901376724243, site loss 0.012633307836949825
Iteration 768, loss 1.3443377017974854, site loss 0.008647693321108818
Iteration 769, loss 1.3156473636627197, site loss 0.010140440426766872
Iteration 770, loss 1.4110875129699707, site loss 0.009591719135642052
Iteration 771, loss 1.3806581497192383, site loss 0.009389654733240604
Iteration 772, loss 1.3445672988891602, site loss 0.010046450421214104
Iteration 773, loss 1.2812066078186035, site loss 0.008157429285347462
Iteration 774, loss 1.5054106712341309, site loss 0.0119650699198246
Iteration 775, loss 1.3494441509246826, site loss 0.010460469871759415
Iteration 776, loss 1.368470311164856, site loss 0.010642649605870247
Iteration 777, loss 1.433954119682312, site loss 0.010959584265947342
Iteration 778, loss 1.4561493396759033, site loss 0.01309521496295929
Iteration 779, loss 1.3717703819274902, site loss 0.011829201132059097
Iteration 780, loss 1.3906834125518799, site loss 0.011664912104606628
Iteration 781, loss 1.388987421989441, site loss 0.010961821302771568
Iteration 782, loss 1.4311470985412598, site loss 0.011724505573511124
Iteration 783, loss 1.4789263010025024, site loss 0.012714346870779991
Iteration 784, loss 1.5377616882324219, site loss 0.01201418787240982
Iteration 785, loss 1.3671343326568604, site loss 0.010116285644471645
Iteration 786, loss 1.4194552898406982, site loss 0.012979760766029358
Iteration 787, loss 1.474527359008789, site loss 0.012009300291538239
Iteration 788, loss 1.4692212343215942, site loss 0.013003664091229439
Iteration 789, loss 1.4031716585159302, site loss 0.011298657394945621
Iteration 790, loss 1.3957247734069824, site loss 0.010391924530267715
Iteration 791, loss 1.3864569664001465, site loss 0.010554242879152298
Iteration 792, loss 1.3186416625976562, site loss 0.010012466460466385
Iteration 793, loss 1.3112561702728271, site loss 0.01089412346482277
Iteration 794, loss 1.3855233192443848, site loss 0.010528389364480972
Iteration 795, loss 1.3802331686019897, site loss 0.011090944521129131
Iteration 796, loss 1.3720500469207764, site loss 0.010781079530715942
Iteration 797, loss 1.283603310585022, site loss 0.0085210632532835
Iteration 798, loss 1.2851321697235107, site loss 0.009112372994422913
Iteration 799, loss 1.3527412414550781, site loss 0.011752751655876637
Iteration 800, loss 1.3792310953140259, site loss 0.010848917067050934
Iteration 801, loss 1.360710859298706, site loss 0.010008784011006355
Iteration 802, loss 1.4694451093673706, site loss 0.013135917484760284
Iteration 803, loss 1.281538724899292, site loss 0.008445244282484055
Iteration 804, loss 1.3506567478179932, site loss 0.012364450842142105
Iteration 805, loss 1.354832410812378, site loss 0.0108729787170887
Iteration 806, loss 1.5857418775558472, site loss 0.02008272334933281
Iteration 807, loss 1.3674602508544922, site loss 0.010110714472830296
Iteration 808, loss 1.3762779235839844, site loss 0.009997401386499405
Iteration 809, loss 1.3329875469207764, site loss 0.008596193045377731
Iteration 810, loss 1.3897262811660767, site loss 0.0105760358273983
Iteration 811, loss 1.3978537321090698, site loss 0.012723175808787346
Iteration 812, loss 1.4166717529296875, site loss 0.01090359129011631
Iteration 813, loss 1.3280112743377686, site loss 0.00932843517512083
Iteration 814, loss 1.322959542274475, site loss 0.00996508076786995
Iteration 815, loss 1.3917266130447388, site loss 0.011329407803714275
Iteration 816, loss 1.3649877309799194, site loss 0.008556611835956573
Iteration 817, loss 1.404971957206726, site loss 0.009916606359183788
Iteration 818, loss 1.3370566368103027, site loss 0.009999969974160194
Iteration 819, loss 1.3309729099273682, site loss 0.00975927896797657
Iteration 820, loss 1.2592105865478516, site loss 0.008411471731960773
Iteration 821, loss 1.3150908946990967, site loss 0.0086077144369483
Iteration 822, loss 1.2818676233291626, site loss 0.009575513191521168
Iteration 823, loss 1.3213616609573364, site loss 0.008841641247272491
Iteration 824, loss 1.2635148763656616, site loss 0.007626544218510389
Iteration 825, loss 1.358016848564148, site loss 0.010943571105599403
Iteration 826, loss 1.3140966892242432, site loss 0.00976129062473774
Iteration 827, loss 1.3235526084899902, site loss 0.01097808312624693
Iteration 828, loss 1.338038444519043, site loss 0.010882909409701824
Iteration 829, loss 1.3203320503234863, site loss 0.010509194806218147
Iteration 830, loss 1.2371959686279297, site loss 0.010206506587564945
Iteration 831, loss 1.3035190105438232, site loss 0.009274063631892204
Iteration 832, loss 1.314819097518921, site loss 0.007944336161017418
Iteration 833, loss 1.363776445388794, site loss 0.010538510978221893
Iteration 834, loss 1.4006330966949463, site loss 0.010041678324341774
Iteration 835, loss 1.3188776969909668, site loss 0.010377759113907814
Iteration 836, loss 1.3020840883255005, site loss 0.008974157273769379
Iteration 837, loss 1.3590576648712158, site loss 0.011824799701571465
Iteration 838, loss 1.3291709423065186, site loss 0.01019596029073
Iteration 839, loss 1.326526403427124, site loss 0.008535010740160942
Iteration 840, loss 1.2585057020187378, site loss 0.00892011821269989
Iteration 841, loss 1.3549164533615112, site loss 0.008883077651262283
Iteration 842, loss 1.2662460803985596, site loss 0.00914300698786974
Iteration 843, loss 1.286407232284546, site loss 0.00968351773917675
Iteration 844, loss 1.3250362873077393, site loss 0.010381504893302917
Iteration 845, loss 1.3363072872161865, site loss 0.009713323786854744
Iteration 846, loss 1.324540138244629, site loss 0.009450490586459637
Iteration 847, loss 1.3353804349899292, site loss 0.010912442579865456
Iteration 848, loss 1.3120907545089722, site loss 0.008867576718330383
Iteration 849, loss 1.3073387145996094, site loss 0.010885040275752544
Iteration 850, loss 1.2819652557373047, site loss 0.007822760380804539
Iteration 851, loss 1.2300714254379272, site loss 0.0076400404796004295
Iteration 852, loss 1.3558580875396729, site loss 0.010681241750717163
Iteration 853, loss 1.175909399986267, site loss 0.007132916245609522
Iteration 854, loss 1.306680679321289, site loss 0.008961314335465431
Iteration 855, loss 1.2528300285339355, site loss 0.009973552078008652
Iteration 856, loss 1.3777786493301392, site loss 0.011288536712527275
Iteration 857, loss 1.2550785541534424, site loss 0.008075087331235409
Iteration 858, loss 1.2587573528289795, site loss 0.010183151811361313
Iteration 859, loss 1.227308988571167, site loss 0.007852491922676563
Iteration 860, loss 1.1910521984100342, site loss 0.008254284970462322
Iteration 861, loss 1.2225518226623535, site loss 0.007449878845363855
Iteration 862, loss 1.2189024686813354, site loss 0.008037304505705833
Iteration 863, loss 1.2552025318145752, site loss 0.007762435358017683
Iteration 864, loss 1.3066262006759644, site loss 0.011014392599463463
Iteration 865, loss 1.3275642395019531, site loss 0.010551253333687782
Iteration 866, loss 1.2407832145690918, site loss 0.008641215972602367
Iteration 867, loss 1.2895684242248535, site loss 0.009241213090717793
Iteration 868, loss 1.2467336654663086, site loss 0.008869780227541924
Iteration 869, loss 1.329480528831482, site loss 0.009071039035916328
Iteration 870, loss 1.2339885234832764, site loss 0.009625482372939587
Iteration 871, loss 1.2470628023147583, site loss 0.008457111194729805
Iteration 872, loss 1.2945306301116943, site loss 0.01032663881778717
Iteration 873, loss 1.3020009994506836, site loss 0.01080147735774517
Iteration 874, loss 1.2900476455688477, site loss 0.01121826097369194
Iteration 875, loss 1.32502019405365, site loss 0.009831544943153858
Iteration 876, loss 1.301793098449707, site loss 0.00843241810798645
Iteration 877, loss 1.3058483600616455, site loss 0.009436366148293018
Iteration 878, loss 1.285401701927185, site loss 0.00960986316204071
Iteration 879, loss 1.2293760776519775, site loss 0.007847454398870468
Iteration 880, loss 1.1982237100601196, site loss 0.007663071155548096
Iteration 881, loss 1.3036091327667236, site loss 0.008995870128273964
Iteration 882, loss 1.2185837030410767, site loss 0.007693345192819834
Iteration 883, loss 1.263275384902954, site loss 0.008264534175395966
Iteration 884, loss 1.2079613208770752, site loss 0.009519544430077076
Iteration 885, loss 1.1677403450012207, site loss 0.00811050832271576
Iteration 886, loss 1.3011963367462158, site loss 0.00828648917376995
Iteration 887, loss 1.2925910949707031, site loss 0.008603180758655071
Iteration 888, loss 1.332970380783081, site loss 0.008719321340322495
Iteration 889, loss 1.2688491344451904, site loss 0.007163085043430328
Iteration 890, loss 1.300250768661499, site loss 0.006483887787908316
Iteration 891, loss 1.2836198806762695, site loss 0.008426858112215996
Iteration 892, loss 1.308170199394226, site loss 0.008999498561024666
Iteration 893, loss 1.2995792627334595, site loss 0.00992119126021862
Iteration 894, loss 1.2836859226226807, site loss 0.009222777560353279
Iteration 895, loss 1.263839840888977, site loss 0.009521527215838432
Iteration 896, loss 1.2135732173919678, site loss 0.007606402039527893
Iteration 897, loss 1.2689900398254395, site loss 0.007521923631429672
Iteration 898, loss 1.265742301940918, site loss 0.009853038936853409
Iteration 899, loss 1.2192649841308594, site loss 0.007984934374690056
Iteration 900, loss 1.2699854373931885, site loss 0.007838260382413864
Iteration 901, loss 1.3387305736541748, site loss 0.009666326455771923
Iteration 902, loss 1.1969425678253174, site loss 0.007810661569237709
Iteration 903, loss 1.3042018413543701, site loss 0.009728491306304932
Iteration 904, loss 1.2388150691986084, site loss 0.007448467426002026
Iteration 905, loss 1.2898938655853271, site loss 0.00896781962364912
Iteration 906, loss 1.3837957382202148, site loss 0.009172715246677399
Iteration 907, loss 1.2894346714019775, site loss 0.008845675736665726
Iteration 908, loss 1.2131524085998535, site loss 0.007211429998278618
Iteration 909, loss 1.1661328077316284, site loss 0.009121757000684738
Iteration 910, loss 1.2774617671966553, site loss 0.010168362408876419
Iteration 911, loss 1.1613492965698242, site loss 0.006942751817405224
Iteration 912, loss 1.2127079963684082, site loss 0.00946013256907463
Iteration 913, loss 1.2809946537017822, site loss 0.006989271380007267
Iteration 914, loss 1.2987794876098633, site loss 0.009040948003530502
Iteration 915, loss 1.2756786346435547, site loss 0.008382739499211311
Iteration 916, loss 1.2576072216033936, site loss 0.009871597401797771
Iteration 917, loss 1.2399036884307861, site loss 0.010079656727612019
Iteration 918, loss 1.2299635410308838, site loss 0.008813291788101196
Iteration 919, loss 1.3006938695907593, site loss 0.009199483320116997
Iteration 920, loss 1.2859065532684326, site loss 0.0064143231138587
Iteration 921, loss 1.3252733945846558, site loss 0.009943470358848572
Iteration 922, loss 1.2165169715881348, site loss 0.00782067608088255
Iteration 923, loss 1.315263032913208, site loss 0.008875567466020584
Iteration 924, loss 1.3451869487762451, site loss 0.00920330360531807
Iteration 925, loss 1.3720115423202515, site loss 0.007920249365270138
Iteration 926, loss 1.3085951805114746, site loss 0.007692089304327965
Iteration 927, loss 1.3066842555999756, site loss 0.008635051548480988
Iteration 928, loss 1.3884168863296509, site loss 0.009593134745955467
Iteration 929, loss 1.3128435611724854, site loss 0.008674437180161476
Iteration 930, loss 1.3042151927947998, site loss 0.00965159386396408
Iteration 931, loss 1.5123059749603271, site loss 0.01900082267820835
Iteration 932, loss 1.2934726476669312, site loss 0.011692251078784466
Iteration 933, loss 1.3553988933563232, site loss 0.009208855219185352
Iteration 934, loss 1.2925097942352295, site loss 0.00830790400505066
Iteration 935, loss 1.3949370384216309, site loss 0.008151537738740444
Iteration 936, loss 1.3523284196853638, site loss 0.008510278537869453
Iteration 937, loss 1.257773995399475, site loss 0.008034118451178074
Iteration 938, loss 1.3637889623641968, site loss 0.010696039535105228
Iteration 939, loss 1.4185497760772705, site loss 0.01075197383761406
Iteration 940, loss 1.3590202331542969, site loss 0.009087739512324333
Iteration 941, loss 1.4069435596466064, site loss 0.009095006622374058
Iteration 942, loss 1.247417688369751, site loss 0.007912092842161655
Iteration 943, loss 1.288654088973999, site loss 0.007405892945826054
Iteration 944, loss 1.4050731658935547, site loss 0.010840162634849548
Iteration 945, loss 1.3400530815124512, site loss 0.007874934002757072
Iteration 946, loss 1.2745563983917236, site loss 0.0064386036247015
Iteration 947, loss 1.314162015914917, site loss 0.009198426268994808
Iteration 948, loss 1.3651793003082275, site loss 0.009974059648811817
Iteration 949, loss 1.3750996589660645, site loss 0.007194609846919775
Iteration 950, loss 1.2433103322982788, site loss 0.007849102839827538
Iteration 951, loss 1.2802485227584839, site loss 0.00823359377682209
Iteration 952, loss 1.3045833110809326, site loss 0.008010867983102798
Iteration 953, loss 1.2186312675476074, site loss 0.007260060869157314
Iteration 954, loss 1.2614853382110596, site loss 0.008486364968121052
Iteration 955, loss 1.2249878644943237, site loss 0.00899599865078926
Iteration 956, loss 1.3422176837921143, site loss 0.01034155860543251
Iteration 957, loss 1.256173849105835, site loss 0.007743857800960541
Iteration 958, loss 1.319250226020813, site loss 0.007718934211879969
Iteration 959, loss 1.2267537117004395, site loss 0.009329436346888542
Iteration 960, loss 1.3357207775115967, site loss 0.00941135548055172
Iteration 961, loss 1.2251209020614624, site loss 0.008966278284788132
Iteration 962, loss 1.2981271743774414, site loss 0.008132996037602425
Iteration 963, loss 1.3239864110946655, site loss 0.008673257194459438
Iteration 964, loss 1.357021450996399, site loss 0.008041135966777802
Iteration 965, loss 1.314650535583496, site loss 0.008817348629236221
Iteration 966, loss 1.3202028274536133, site loss 0.00696534151211381
Iteration 967, loss 1.2140381336212158, site loss 0.0069388472475111485
Iteration 968, loss 1.3466317653656006, site loss 0.007401885464787483
Iteration 969, loss 1.2860760688781738, site loss 0.008428887464106083
Iteration 970, loss 1.255584716796875, site loss 0.00947347842156887
Iteration 971, loss 1.3493101596832275, site loss 0.009163030423223972
Iteration 972, loss 1.4100847244262695, site loss 0.012072991579771042
Iteration 973, loss 1.264263391494751, site loss 0.008898737840354443
Iteration 974, loss 1.3487813472747803, site loss 0.012945747002959251
Iteration 975, loss 1.3069543838500977, site loss 0.010084254667162895
Iteration 976, loss 1.342106580734253, site loss 0.009721025824546814
Iteration 977, loss 1.4311639070510864, site loss 0.011998096480965614
Iteration 978, loss 1.3242849111557007, site loss 0.008532162755727768
Iteration 979, loss 1.3466377258300781, site loss 0.00939640961587429
Iteration 980, loss 1.398719072341919, site loss 0.009607367217540741
Iteration 981, loss 1.3700382709503174, site loss 0.009989531710743904
Iteration 982, loss 1.4151612520217896, site loss 0.010495219379663467
Iteration 983, loss 1.2930694818496704, site loss 0.009568005800247192
Iteration 984, loss 1.3733892440795898, site loss 0.009374994784593582
Iteration 985, loss 1.3333094120025635, site loss 0.00912962481379509
Iteration 986, loss 1.251598596572876, site loss 0.009062880650162697
Iteration 987, loss 1.2827508449554443, site loss 0.008160100318491459
Iteration 988, loss 1.2627739906311035, site loss 0.008911101147532463
Iteration 989, loss 1.2256207466125488, site loss 0.009160170331597328
Iteration 990, loss 1.3146625757217407, site loss 0.009967670775949955
Iteration 991, loss 1.2967498302459717, site loss 0.009638601914048195
Iteration 992, loss 1.3369274139404297, site loss 0.007824818603694439
Iteration 993, loss 1.287433385848999, site loss 0.01110921148210764
Iteration 994, loss 1.245136022567749, site loss 0.008313082158565521
Iteration 995, loss 1.2610440254211426, site loss 0.01024575810879469
Iteration 996, loss 1.286426067352295, site loss 0.008367298170924187
Iteration 997, loss 1.265378713607788, site loss 0.00789642333984375
Iteration 998, loss 1.3081022500991821, site loss 0.008722792379558086
Iteration 999, loss 1.2164268493652344, site loss 0.010367412120103836
embed_matrix_0
[[ 9.45316315e-01 -6.63625717e-01 -2.47278929e-01 -7.91995525e-01
   2.66303062e-01 -6.48389816e-01  4.97818947e-01  3.40559959e-01
   2.15496302e-01 -8.56987476e-01]
 [ 3.83930057e-01  3.92466098e-01 -1.53173351e+00  2.00248599e+00
  -1.39475989e+00  2.31676698e+00 -1.19107699e+00  1.90463936e+00
   4.32272851e-01  2.17376685e+00]
 [-2.35772324e+00 -1.15055406e+00 -1.99622488e+00 -7.47745112e-02
  -3.45795774e+00  1.09140408e+00 -7.54873231e-02  5.13258934e-01
   1.64636719e+00  1.14518988e+00]
 [-3.98358917e+00 -2.82311112e-01 -2.01754808e+00  1.82841241e+00
  -1.43880522e+00  1.82803106e+00  3.79113972e-01  1.54039264e-01
  -4.51503582e-02  7.56153047e-01]
 [-2.22083068e+00 -8.52681160e-01 -2.04856443e+00 -8.19472432e-01
  -2.59211874e+00  7.95609355e-01 -6.42791092e-02  2.66143394e+00
   1.05656779e+00  1.45006478e+00]
 [-2.96186972e+00 -2.00810361e+00 -1.33309329e+00  2.57848096e+00
   8.20554256e-01  1.25393546e+00 -1.13131499e+00  2.21775031e+00
   1.67922020e+00 -1.83464259e-01]
 [-1.40075731e+00 -2.04879785e+00 -1.32922435e+00  1.92631412e+00
  -1.56690907e+00  9.09434676e-01 -1.55715942e+00  2.83820629e+00
   1.60419452e+00 -4.07036275e-01]
 [-9.45507467e-01 -1.74928749e+00 -2.19265795e+00  2.09435892e+00
  -8.88350725e-01  5.17634511e-01  8.16006541e-01  1.60203075e+00
  -2.51008630e-01  2.56443596e+00]
 [-6.14135921e-01 -1.65809309e+00 -2.85566926e+00  2.20200658e+00
  -4.71569180e-01  1.00067139e+00 -2.77654558e-01  8.13814223e-01
  -2.03163162e-01  2.58036900e+00]
 [-2.91480875e+00  3.76545697e-01 -2.66040730e+00  1.72815967e+00
   2.78220892e-01  7.21985400e-01  3.33451211e-01  1.78122187e+00
   1.41775358e+00  1.97550750e+00]
 [-7.06868470e-01 -5.64206183e-01 -2.64062500e+00  1.81024957e+00
  -2.24756932e+00  9.01472628e-01 -3.74210507e-01  1.85085785e+00
   1.65458763e+00  7.39733934e-01]
 [-4.11360931e+00 -2.02880979e+00  3.36252272e-01  1.86020172e+00
  -1.45614004e+00  1.50814223e+00 -1.35340798e+00 -2.55703998e+00
   9.45748538e-02  3.13413954e+00]
 [ 1.65531591e-01 -2.31890410e-01  3.98530662e-01 -2.89011478e-01
  -1.30503786e+00  9.51870680e-02 -1.35359538e+00  9.57309604e-02
  -4.97069895e-01  7.37379313e-01]
 [-1.83332324e+00 -6.78308725e-01  1.52603090e+00  2.62230301e+00
  -1.36322284e+00  9.73321915e-01  1.97018623e+00  2.24496675e+00
   1.84930372e+00  2.39732695e+00]
 [ 1.12350866e-01 -3.36626005e+00 -1.40063345e+00 -5.37222445e-01
   4.77793843e-01  2.08080506e+00  5.48187494e-02  5.66307664e-01
   3.88522720e+00  3.30164361e+00]
 [-7.29365587e-01 -2.31734800e+00 -2.54148871e-01  2.10809946e+00
  -2.25046825e+00  3.67645979e-01 -7.73489356e-01  1.38754916e+00
  -1.60250485e-01  2.42552233e+00]
 [-1.22459745e+00 -9.40896749e-01 -1.35403454e-01  6.09140635e-01
  -8.98438573e-01  2.22672486e+00 -2.18296862e+00  1.81787610e+00
  -3.13153625e-01  2.72376633e+00]
 [-1.06375289e+00  1.19331487e-01 -4.64664370e-01  4.96905327e-01
  -6.70604289e-01  2.73782825e+00 -1.99194622e+00  2.01020837e+00
   5.42222941e-03  2.80866098e+00]
 [-6.27917230e-01 -5.21303415e-01 -1.03823566e+00  1.50477552e+00
  -1.32855654e+00  4.43114424e+00  5.21794200e-01  9.69531178e-01
  -8.04697752e-01  1.34595907e+00]
 [-2.01596189e+00 -1.31897306e+00 -1.15984952e+00  7.95389056e-01
  -1.15526950e+00  4.40219498e+00  9.27828431e-01  1.30539942e+00
  -1.37449145e+00  5.36660671e-01]
 [-4.55638111e-01 -2.32417345e+00 -1.15715422e-01  2.07802916e+00
  -2.76398158e+00  5.15586948e+00  4.36915487e-01 -6.12829864e-01
   8.32213402e-01 -6.36743724e-01]
 [-3.40221494e-01  7.95409501e-01 -1.00608873e+00  1.91484082e+00
  -1.57658660e+00  2.70164824e+00 -1.72289228e+00  6.11189306e-01
   1.14138496e+00  2.39261770e+00]
 [ 4.87070113e-01 -4.68832701e-01  8.42597842e-01 -3.70283052e-03
   8.31934631e-01  3.66315514e-01  4.47019607e-01  4.68586773e-01
  -6.73188686e-01  4.69465889e-02]
 [-2.48415232e-01 -7.88476467e-02 -9.73341703e-01  2.60946274e-01
   2.70831823e-01 -6.11693859e-02 -3.55926037e-01 -9.20017242e-01
   4.56774712e-01 -3.18113089e-01]
 [ 2.72086430e+00  1.84420288e+00 -2.26669526e+00 -8.20273876e-01
  -1.86714339e+00  4.08705282e+00  2.30055785e+00 -1.26412416e+00
   3.50133657e+00 -1.22492993e+00]
 [-4.00534391e-01 -4.29186821e-01 -6.91769838e-01  6.94278955e-01
   7.95188427e-01 -4.03327703e-01 -5.20312071e-01  6.78691626e-01
  -2.57214785e-01  5.92465878e-01]]
rnn/mlstm/mlstm/wx_0
[[ 0.13591333  0.20476301 -0.44928432 ...  0.50338674  0.3187794
  -0.05481836]
 [ 0.00249574  0.25909033  0.02700497 ...  0.38889122  0.14128451
  -0.07986668]
 [ 0.51784956  0.29715848 -0.12135425 ...  0.4590274   0.12185366
   0.10275473]
 ...
 [ 0.24942887 -0.54156995  0.13001315 ... -0.38084096 -0.49093193
  -0.17328191]
 [ 0.32901722 -0.63432485  0.13302204 ... -0.35607588  0.05398509
   0.07483019]
 [-0.20451519 -0.39909053 -0.04947459 ... -0.06057698 -0.16170985
  -0.25748163]]
rnn/mlstm/mlstm/wh_0
[[-0.0959952  -0.13734825 -0.0534667  ...  0.11811852 -0.09561936
  -0.04578298]
 [ 0.04130835 -0.08273108  0.01813831 ... -0.08964977 -0.05034361
   0.04085309]
 [-0.0153087  -0.05465198 -0.02113438 ...  0.03637807  0.12969024
   0.1390225 ]
 ...
 [ 0.07623739  0.17670657 -0.01258959 ... -0.12621571  0.02772299
   0.04462383]
 [-0.03943524 -0.02749317 -0.04625834 ... -0.03712094 -0.02175092
  -0.06584734]
 [ 0.01103237  0.03730058  0.00947449 ... -0.09060141  0.0587911
   0.06273528]]
rnn/mlstm/mlstm/wmx_0
[[ 0.3824302   0.7361987   0.07257926 ...  1.0254505   0.12720971
  -0.08745105]
 [ 0.1919942   0.12137306 -1.079857   ...  0.04906245  0.1264982
  -0.01728408]
 [-0.01358619 -0.33221522  0.09168078 ... -0.08281019  0.20417851
   0.18191695]
 ...
 [ 0.16994692  0.6111441  -0.06164561 ...  0.08644017 -0.20028542
   0.4691206 ]
 [ 0.3426797  -0.05781324 -0.2931392  ... -0.09778024  0.00421549
  -0.07924173]
 [-0.47806287 -0.24840525  0.05529941 ... -0.01786741 -0.33704332
   0.40921238]]
rnn/mlstm/mlstm/wmh_0
[[ 0.11286357 -0.13689874  0.0085525  ... -0.11363865  0.05442432
  -0.05759985]
 [ 0.07824938 -0.0017412  -0.09835926 ... -0.0546634   0.10268113
  -0.07892624]
 [ 0.06358919  0.03393447 -0.06428291 ... -0.01695627 -0.12246627
  -0.01702828]
 ...
 [ 0.01224696 -0.01257737  0.02779799 ...  0.10926439 -0.04773615
  -0.04668061]
 [-0.1048447  -0.01944469 -0.01379786 ...  0.08080803 -0.11468817
   0.07767067]
 [ 0.08119249  0.08744273 -0.0491201  ... -0.18527712  0.02205364
   0.19583738]]
rnn/mlstm/mlstm/b_0
[2.877773  2.7679977 2.9447987 ... 3.042665  2.9773796 2.9957247]
rnn/mlstm/mlstm/gx_0
[0.57052547 0.83185357 1.001372   ... 0.83157533 0.83069885 0.9042669 ]
rnn/mlstm/mlstm/gh_0
[1.6201919 1.1085644 1.3018073 ... 0.9642134 1.0746017 0.9239057]
rnn/mlstm/mlstm/gmx_0
[1.5817949 1.7930588 1.9247621 ... 1.2134557 1.2561221 1.3543391]
rnn/mlstm/mlstm/gmh_0
[1.5814409 1.7920394 1.9238728 ... 1.2129769 1.255866  1.353846 ]
fully_connected/weights_0
[[-5.0791036e-02 -1.6908509e-01 -3.6725011e-01 ... -1.1383758e-01
  -1.6334297e-01 -5.6175089e-01]
 [ 2.3578358e-04  5.0439745e-02 -8.5378513e-03 ...  8.8680704e-04
  -9.6372887e-03  2.5007922e-02]
 [-2.3252109e-01 -2.8688413e-01 -4.4807363e-01 ...  3.7494183e-03
   6.8959840e-02 -6.2061492e-03]
 ...
 [ 3.6279991e-02 -2.9898020e-02  3.8887812e-03 ...  1.5692274e-03
   3.3295529e-03 -8.0414049e-02]
 [ 9.8252423e-02 -2.7251825e-02 -8.2661100e-02 ...  3.0429959e-02
   4.7274943e-02  4.8478153e-02]
 [-1.7275451e-01  1.8812418e-02 -1.0247985e-01 ...  6.6167578e-02
   5.4896660e-02 -7.0934251e-02]]
fully_connected/biases_0
[ -1.6590034   -0.19421984  -1.2318509   -0.05036132  -0.6024646
  -0.32217482  -0.25169992  -0.8597735   -0.8018915   -0.96207166
  -1.3236399   -9.846551    -0.5648262   -0.42638537  -0.8925787
  -0.9930373   -1.1596243   -1.3374628   -1.4637463   -1.9607242
  -0.63547575 -10.209306   -10.212627   -10.204994     1.2829455 ]
fully_connected_1/weights_0
[[-0.0103362  -0.05066273 -0.10658452]
 [ 0.01086971 -0.06394462 -0.00809708]
 [-0.00593118 -0.03637129 -0.07010455]
 ...
 [ 0.00793194 -0.03273097 -0.02980066]
 [ 0.00999584 -0.01317691  0.08451442]
 [ 0.00942544 -0.03570665 -0.05209455]]
fully_connected_1/biases_0
[ 0.01518521 -0.01753565 -0.01255781]
Traceback (most recent call last):
  File "train_script.py", line 152, in <module>
    np.save('{args.save_dir}/losses.npy', losses)
  File "/global/software/sl-7.x86_64/modules/apps/ml/tensorflow/1.12.0-py36/lib/python3.6/site-packages/numpy/lib/npyio.py", line 524, in save
    fid = open(file, "wb")
FileNotFoundError: [Errno 2] No such file or directory: '{args.save_dir}/losses.npy'
